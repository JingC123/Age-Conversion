{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "599.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ahNbtJSsy8"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StN3gn39SveT"
      },
      "source": [
        "import torch\r\n",
        "print('Version', torch.__version__)\r\n",
        "print('CUDA enabled:', torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pqR3yX9KoDV"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')\r\n",
        "!ls /gdrive\r\n",
        "\r\n",
        "import os\r\n",
        "BASE_PATH = '/gdrive/My Drive/colab_files/599project/'\r\n",
        "if not os.path.exists(BASE_PATH):\r\n",
        "    os.makedirs(BASE_PATH)\r\n",
        "os.chdir(BASE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1guiE_RMNx"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwSDcGt1hsMc"
      },
      "source": [
        "! pip install -q kaggle\r\n",
        "from google.colab import files\r\n",
        "import shutil\r\n",
        "\r\n",
        "files.upload()\r\n",
        "! mkdir ~/.kaggle\r\n",
        "\r\n",
        "! cp kaggle.json ~/.kaggle/\r\n",
        "! chmod 600 ~/.kaggle/kaggle.json\r\n",
        "! kaggle datasets download -d frabbisw/facial-age\r\n",
        "! unzip facial-age\r\n",
        "! rm facial-age.zip\r\n",
        "\r\n",
        "if not os.path.exists('dataset'):\r\n",
        "  os.makedirs('dataset')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSvkONAth648"
      },
      "source": [
        "! mkdir ./dataset/trainA\r\n",
        "! mkdir ./dataset/trainB\r\n",
        "! mkdir ./dataset/testA\r\n",
        "! mkdir ./dataset/testB\r\n",
        "\r\n",
        "import os\r\n",
        "from skimage import io, transform\r\n",
        "def get_file_paths(folder):\r\n",
        "    image_file_paths = []\r\n",
        "    for root, dirs, filenames in os.walk(folder):\r\n",
        "        filenames = sorted(filenames)\r\n",
        "        for filename in filenames:\r\n",
        "            input_path = os.path.abspath(root)\r\n",
        "            file_path = os.path.join(input_path, filename)\r\n",
        "            if filename.endswith('.png') or filename.endswith('.jpg'):\r\n",
        "                image_file_paths.append(file_path)\r\n",
        "\r\n",
        "        break  # prevent descending into subfolders\r\n",
        "    return image_file_paths\r\n",
        "\r\n",
        "def getdataset(folder, minAge, maxAge):\r\n",
        "  # A: age 20 - age 40\r\n",
        "  for i in range(minAge, maxAge):\r\n",
        "      name = BASE_PATH + '/face_age/' + '0' + str(i) + '/'\r\n",
        "      path = get_file_paths(name)\r\n",
        "      length = len(path)\r\n",
        "      for i in range(int(0.8 * length)):\r\n",
        "        new_path = BASE_PATH + '/dataset/train' + folder + '/' + path[i].split('/')[-1]\r\n",
        "        img = io.imread(path[i])\r\n",
        "        img = transform.resize(img, (256, 256))\r\n",
        "        io.imsave(new_path, img) \r\n",
        "      for i in range(int(0.8 * length), length):\r\n",
        "        new_path = BASE_PATH + '/dataset/test' + folder + '/' + path[i].split('/')[-1]\r\n",
        "        img = io.imread(path[i])\r\n",
        "        img = transform.resize(img, (256, 256))\r\n",
        "        io.imsave(new_path, img) \r\n",
        "\r\n",
        "getdataset('A', 20, 30)\r\n",
        "getdataset('B', 70, 80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgoaan06ww9x"
      },
      "source": [
        "TARGET_DIR = BASE_PATH + '/dataset/'\r\n",
        "!mkdir -p \"$TARGET_DIR/train\" \"$TARGET_DIR/test\"\r\n",
        "!mv \"$TARGET_DIR/trainA\" \"$TARGET_DIR/train/A\"\r\n",
        "!mv \"$TARGET_DIR/trainB\" \"$TARGET_DIR/train/B\"\r\n",
        "!mv \"$TARGET_DIR/testA\" \"$TARGET_DIR/test/A\"\r\n",
        "!mv \"$TARGET_DIR/testB\" \"$TARGET_DIR/test/B\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGjmIubZRLaa"
      },
      "source": [
        "import glob\r\n",
        "import random\r\n",
        "import os\r\n",
        "\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from PIL import Image\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "class ImageDataset(Dataset):\r\n",
        "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\r\n",
        "        self.transform = transforms.Compose(transforms_)\r\n",
        "        self.unaligned = unaligned\r\n",
        "\r\n",
        "        self.files_A = sorted(glob.glob(os.path.join(root, '%s/A' % mode) + '/*.*'))\r\n",
        "        self.files_B = sorted(glob.glob(os.path.join(root, '%s/B' % mode) + '/*.*'))\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\r\n",
        "\r\n",
        "        if self.unaligned:\r\n",
        "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\r\n",
        "        else:\r\n",
        "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\r\n",
        "\r\n",
        "        return {'A': item_A, 'B': item_B}\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return max(len(self.files_A), len(self.files_B))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4xfoOm-QwUA"
      },
      "source": [
        "## Define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZTQGvatqwPG"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "class ResidualBlock(nn.Module):\r\n",
        "    def __init__(self, in_features):\r\n",
        "        super(ResidualBlock, self).__init__()\r\n",
        "\r\n",
        "        conv_block = [  nn.ReflectionPad2d(1),\r\n",
        "                        nn.Conv2d(in_features, in_features, 3),\r\n",
        "                        nn.InstanceNorm2d(in_features),\r\n",
        "                        nn.ReLU(inplace=True),\r\n",
        "                        nn.ReflectionPad2d(1),\r\n",
        "                        nn.Conv2d(in_features, in_features, 3),\r\n",
        "                        nn.InstanceNorm2d(in_features)  ]\r\n",
        "\r\n",
        "        self.conv_block = nn.Sequential(*conv_block)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return x + self.conv_block(x)\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "\r\n",
        "        # Initial convolution block       \r\n",
        "        model = [   nn.ReflectionPad2d(3),\r\n",
        "                    nn.Conv2d(input_nc, 64, 7),\r\n",
        "                    nn.InstanceNorm2d(64),\r\n",
        "                    nn.ReLU(inplace=True) ]\r\n",
        "\r\n",
        "        # Downsampling\r\n",
        "        in_features = 64\r\n",
        "        out_features = in_features*2\r\n",
        "        for _ in range(2):\r\n",
        "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\r\n",
        "                        nn.InstanceNorm2d(out_features),\r\n",
        "                        nn.ReLU(inplace=True) ]\r\n",
        "            in_features = out_features\r\n",
        "            out_features = in_features*2\r\n",
        "\r\n",
        "        # Residual blocks\r\n",
        "        for _ in range(n_residual_blocks):\r\n",
        "            model += [ResidualBlock(in_features)]\r\n",
        "\r\n",
        "        # Upsampling\r\n",
        "        out_features = in_features//2\r\n",
        "        for _ in range(2):\r\n",
        "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\r\n",
        "                        nn.InstanceNorm2d(out_features),\r\n",
        "                        nn.ReLU(inplace=True) ]\r\n",
        "            in_features = out_features\r\n",
        "            out_features = in_features//2\r\n",
        "\r\n",
        "        # Output layer\r\n",
        "        model += [  nn.ReflectionPad2d(3),\r\n",
        "                    nn.Conv2d(64, output_nc, 7),\r\n",
        "                    nn.Tanh() ]\r\n",
        "\r\n",
        "        self.model = nn.Sequential(*model)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self.model(x)\r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self, input_nc):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "\r\n",
        "        # A bunch of convolutions one after another\r\n",
        "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\r\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\r\n",
        "\r\n",
        "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\r\n",
        "                    nn.InstanceNorm2d(128), \r\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\r\n",
        "\r\n",
        "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\r\n",
        "                    nn.InstanceNorm2d(256), \r\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\r\n",
        "\r\n",
        "        model += [  nn.Conv2d(256, 512, 4, padding=1),\r\n",
        "                    nn.InstanceNorm2d(512), \r\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\r\n",
        "\r\n",
        "        # FCN classification layer\r\n",
        "        model += [nn.Conv2d(512, 1, 4, padding=1)]\r\n",
        "\r\n",
        "        self.model = nn.Sequential(*model)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x =  self.model(x)\r\n",
        "        # Average pooling and flatten\r\n",
        "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqXSR28yR3S5"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLMI6jXrqYD"
      },
      "source": [
        "! npm install -g localtunnel\r\n",
        "\r\n",
        "get_ipython().system_raw('python3 -m pip install visdom')\r\n",
        "get_ipython().system_raw('python3 -m visdom.server -port 8097 >> visdomlog.txt 2>&1 &')   \r\n",
        "get_ipython().system_raw('lt --port 8097 >> url.txt 2>&1 &')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSsu750GR1-Y"
      },
      "source": [
        "import random\r\n",
        "import time\r\n",
        "import datetime\r\n",
        "import sys\r\n",
        "\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch\r\n",
        "from visdom import Visdom\r\n",
        "import numpy as np\r\n",
        "from google.colab import output\r\n",
        "\r\n",
        "def tensor2image(tensor):\r\n",
        "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\r\n",
        "    if image.shape[0] == 1:\r\n",
        "        image = np.tile(image, (3,1,1))\r\n",
        "    return image.astype(np.uint8)\r\n",
        "\r\n",
        "class Logger():\r\n",
        "    def __init__(self, n_epochs, batches_epoch):\r\n",
        "        self.viz = Visdom(port=8097)\r\n",
        "        vis = Visdom(port='8097')  \r\n",
        "        output.serve_kernel_port_as_iframe(8097)\r\n",
        "\r\n",
        "        self.n_epochs = n_epochs\r\n",
        "        self.batches_epoch = batches_epoch\r\n",
        "        self.epoch = 1\r\n",
        "        self.batch = 1\r\n",
        "        self.prev_time = time.time()\r\n",
        "        self.mean_period = 0\r\n",
        "        self.losses = {}\r\n",
        "        self.loss_windows = {}\r\n",
        "        self.image_windows = {}\r\n",
        "\r\n",
        "\r\n",
        "    def log(self, losses=None, images=None):\r\n",
        "        self.mean_period += (time.time() - self.prev_time)\r\n",
        "        self.prev_time = time.time()\r\n",
        "\r\n",
        "        sys.stdout.write('\\rEpoch %03d/%03d [%04d/%04d] -- ' % (self.epoch, self.n_epochs, self.batch, self.batches_epoch))\r\n",
        "\r\n",
        "        for i, loss_name in enumerate(losses.keys()):\r\n",
        "            if loss_name not in self.losses:\r\n",
        "                self.losses[loss_name] = losses[loss_name]\r\n",
        "            else:\r\n",
        "                self.losses[loss_name] += losses[loss_name]\r\n",
        "\r\n",
        "            if (i+1) == len(losses.keys()):\r\n",
        "                sys.stdout.write('%s: %.4f -- ' % (loss_name, self.losses[loss_name]/self.batch))\r\n",
        "            else:\r\n",
        "                sys.stdout.write('%s: %.4f | ' % (loss_name, self.losses[loss_name]/self.batch))\r\n",
        "\r\n",
        "        batches_done = self.batches_epoch*(self.epoch - 1) + self.batch\r\n",
        "        batches_left = self.batches_epoch*(self.n_epochs - self.epoch) + self.batches_epoch - self.batch \r\n",
        "        sys.stdout.write('ETA: %s' % (datetime.timedelta(seconds=batches_left*self.mean_period/batches_done)))\r\n",
        "\r\n",
        "        # Draw images\r\n",
        "        for image_name, tensor in images.items():\r\n",
        "            if image_name not in self.image_windows:\r\n",
        "                self.image_windows[image_name] = self.viz.image(tensor2image(tensor.data), opts={'title':image_name})\r\n",
        "            else:\r\n",
        "                self.viz.image(tensor2image(tensor.data), win=self.image_windows[image_name], opts={'title':image_name})\r\n",
        "\r\n",
        "        # End of epoch\r\n",
        "        if (self.batch % self.batches_epoch) == 0:\r\n",
        "            # Plot losses\r\n",
        "            for loss_name, loss in self.losses.items():\r\n",
        "                if loss_name not in self.loss_windows:\r\n",
        "                    self.loss_windows[loss_name] = self.viz.line(X=np.array([self.epoch]), Y=np.array([loss.cpu().detach()/self.batch]), opts={'xlabel': 'epochs', 'ylabel': loss_name, 'title': loss_name})\r\n",
        "                else:\r\n",
        "                    self.viz.line(X=np.array([self.epoch]), Y=np.array([loss.cpu().detach()/self.batch]), win=self.loss_windows[loss_name], update='append')\r\n",
        "                # Reset losses for next epoch\r\n",
        "                self.losses[loss_name] = 0.0\r\n",
        "\r\n",
        "            self.epoch += 1\r\n",
        "            self.batch = 1\r\n",
        "            sys.stdout.write('\\n')\r\n",
        "        else:\r\n",
        "            self.batch += 1\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "class ReplayBuffer():\r\n",
        "    def __init__(self, max_size=50):\r\n",
        "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\r\n",
        "        self.max_size = max_size\r\n",
        "        self.data = []\r\n",
        "\r\n",
        "    def push_and_pop(self, data):\r\n",
        "        to_return = []\r\n",
        "        for element in data.data:\r\n",
        "            element = torch.unsqueeze(element, 0)\r\n",
        "            if len(self.data) < self.max_size:\r\n",
        "                self.data.append(element)\r\n",
        "                to_return.append(element)\r\n",
        "            else:\r\n",
        "                if random.uniform(0,1) > 0.5:\r\n",
        "                    i = random.randint(0, self.max_size-1)\r\n",
        "                    to_return.append(self.data[i].clone())\r\n",
        "                    self.data[i] = element\r\n",
        "                else:\r\n",
        "                    to_return.append(element)\r\n",
        "        return Variable(torch.cat(to_return))\r\n",
        "\r\n",
        "class LambdaLR():\r\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\r\n",
        "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\r\n",
        "        self.n_epochs = n_epochs\r\n",
        "        self.offset = offset\r\n",
        "        self.decay_start_epoch = decay_start_epoch\r\n",
        "\r\n",
        "    def step(self, epoch):\r\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\r\n",
        "\r\n",
        "def weights_init_normal(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find('Conv') != -1:\r\n",
        "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\r\n",
        "    elif classname.find('BatchNorm2d') != -1:\r\n",
        "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\r\n",
        "        torch.nn.init.constant(m.bias.data, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nijNR-wLSBe-"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxgwSyAkSA9O"
      },
      "source": [
        "#!/usr/bin/python3\r\n",
        "\r\n",
        "import argparse\r\n",
        "import itertools\r\n",
        "import os\r\n",
        "\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.autograd import Variable\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "\r\n",
        "epoch = 63 #starting epoch\r\n",
        "n_epochs = 100 #number of epochs of training\r\n",
        "batchSize = 1 #size of the batches\r\n",
        "dataroot = TARGET_DIR #root directory of the dataset\r\n",
        "lr = 0.0002 #initial learning rate\r\n",
        "decay_epoch = 0 #epoch to start linearly decaying the learning rate to 0 \r\n",
        "size = 256 #size of the data crop (squared assumed)\r\n",
        "input_nc = 3 #number of channels of input data\r\n",
        "output_nc = 3 #number of channels of output data\r\n",
        "cuda = True\r\n",
        "n_cpu = 16 #number of cpu threads to use during batch generation\r\n",
        "\r\n",
        "if not os.path.exists('output'):\r\n",
        "  os.makedirs('output')\r\n",
        "\r\n",
        "if torch.cuda.is_available() and not cuda:\r\n",
        "    print(\"WARNING: You have a CUDA device, so you should probably run with cuda = True\")\r\n",
        "\r\n",
        "###### Definition of variables ######\r\n",
        "# Networks\r\n",
        "netG_A2B = Generator(input_nc, output_nc)\r\n",
        "netG_B2A = Generator(output_nc, input_nc)\r\n",
        "netD_A = Discriminator(input_nc)\r\n",
        "netD_B = Discriminator(output_nc)\r\n",
        "\r\n",
        "if cuda:\r\n",
        "    netG_A2B.cuda()\r\n",
        "    netG_B2A.cuda()\r\n",
        "    netD_A.cuda()\r\n",
        "    netD_B.cuda()\r\n",
        "\r\n",
        "if os.path.exists('output'):\r\n",
        "  netG_A2B.load_state_dict(torch.load('output/netG_A2B.pth'))\r\n",
        "  netG_B2A.load_state_dict(torch.load('output/netG_B2A.pth'))\r\n",
        "  netD_A.load_state_dict(torch.load('output/netD_A.pth'))\r\n",
        "  netD_B.load_state_dict(torch.load('output/netD_B.pth'))  \r\n",
        "else: \r\n",
        "  netG_A2B.apply(weights_init_normal)\r\n",
        "  netG_B2A.apply(weights_init_normal)\r\n",
        "  netD_A.apply(weights_init_normal)\r\n",
        "  netD_B.apply(weights_init_normal)\r\n",
        "\r\n",
        "# Lossess\r\n",
        "criterion_GAN = torch.nn.MSELoss()\r\n",
        "criterion_cycle = torch.nn.L1Loss()\r\n",
        "criterion_identity = torch.nn.L1Loss()\r\n",
        "\r\n",
        "# Optimizers & LR schedulers\r\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\r\n",
        "                                lr=lr, betas=(0.5, 0.999))\r\n",
        "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5, 0.999))\r\n",
        "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5, 0.999))\r\n",
        "\r\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\r\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\r\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\r\n",
        "\r\n",
        "# Inputs & targets memory allocation\r\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\r\n",
        "input_A = Tensor(batchSize, input_nc, size, size)\r\n",
        "input_B = Tensor(batchSize, output_nc, size, size)\r\n",
        "target_real = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\r\n",
        "target_fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\r\n",
        "\r\n",
        "fake_A_buffer = ReplayBuffer()\r\n",
        "fake_B_buffer = ReplayBuffer()\r\n",
        "\r\n",
        "# Dataset loader\r\n",
        "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC), \r\n",
        "                transforms.RandomCrop(size), \r\n",
        "                transforms.RandomHorizontalFlip(),\r\n",
        "                transforms.ToTensor(),\r\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\r\n",
        "dataloader = DataLoader(ImageDataset(dataroot, transforms_=transforms_, unaligned=True), \r\n",
        "                        batch_size=batchSize, shuffle=True, num_workers=n_cpu)\r\n",
        "\r\n",
        "# Loss plot\r\n",
        "logger = Logger(n_epochs, len(dataloader))\r\n",
        "###################################\r\n",
        "\r\n",
        "###### Training ######\r\n",
        "for epoch in range(epoch, n_epochs):\r\n",
        "    for i, batch in enumerate(dataloader):\r\n",
        "        # Set model input\r\n",
        "        real_A = Variable(input_A.copy_(batch['A']))\r\n",
        "        real_B = Variable(input_B.copy_(batch['B']))\r\n",
        "\r\n",
        "        ###### Generators A2B and B2A ######\r\n",
        "        optimizer_G.zero_grad()\r\n",
        "\r\n",
        "        # Identity loss\r\n",
        "        # G_A2B(B) should equal B if real B is fed\r\n",
        "        same_B = netG_A2B(real_B)\r\n",
        "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\r\n",
        "        # G_B2A(A) should equal A if real A is fed\r\n",
        "        same_A = netG_B2A(real_A)\r\n",
        "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\r\n",
        "\r\n",
        "        # GAN loss\r\n",
        "        fake_B = netG_A2B(real_A)\r\n",
        "        pred_fake = netD_B(fake_B)\r\n",
        "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\r\n",
        "\r\n",
        "        fake_A = netG_B2A(real_B)\r\n",
        "        pred_fake = netD_A(fake_A)\r\n",
        "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\r\n",
        "\r\n",
        "        # Cycle loss\r\n",
        "        recovered_A = netG_B2A(fake_B)\r\n",
        "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\r\n",
        "\r\n",
        "        recovered_B = netG_A2B(fake_A)\r\n",
        "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\r\n",
        "\r\n",
        "        # Total loss\r\n",
        "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\r\n",
        "        loss_G.backward()\r\n",
        "        \r\n",
        "        optimizer_G.step()\r\n",
        "        ###################################\r\n",
        "\r\n",
        "        ###### Discriminator A ######\r\n",
        "        optimizer_D_A.zero_grad()\r\n",
        "\r\n",
        "        # Real loss\r\n",
        "        pred_real = netD_A(real_A)\r\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\r\n",
        "\r\n",
        "        # Fake loss\r\n",
        "        fake_A = fake_A_buffer.push_and_pop(fake_A)\r\n",
        "        pred_fake = netD_A(fake_A.detach())\r\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\r\n",
        "\r\n",
        "        # Total loss\r\n",
        "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\r\n",
        "        loss_D_A.backward()\r\n",
        "\r\n",
        "        optimizer_D_A.step()\r\n",
        "        ###################################\r\n",
        "\r\n",
        "        ###### Discriminator B ######\r\n",
        "        optimizer_D_B.zero_grad()\r\n",
        "\r\n",
        "        # Real loss\r\n",
        "        pred_real = netD_B(real_B)\r\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\r\n",
        "        \r\n",
        "        # Fake loss\r\n",
        "        fake_B = fake_B_buffer.push_and_pop(fake_B)\r\n",
        "        pred_fake = netD_B(fake_B.detach())\r\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\r\n",
        "\r\n",
        "        # Total loss\r\n",
        "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\r\n",
        "        loss_D_B.backward()\r\n",
        "\r\n",
        "        optimizer_D_B.step()\r\n",
        "        ###################################\r\n",
        "\r\n",
        "        # Progress report (http://localhost:8097)\r\n",
        "        logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B), 'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\r\n",
        "                    'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)}, \r\n",
        "                    images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\r\n",
        "\r\n",
        "    # Update learning rates\r\n",
        "    lr_scheduler_G.step()\r\n",
        "    lr_scheduler_D_A.step()\r\n",
        "    lr_scheduler_D_B.step()\r\n",
        "\r\n",
        "    # Save models checkpoints\r\n",
        "    torch.save(netG_A2B.state_dict(), 'output/netG_A2B.pth')\r\n",
        "    torch.save(netG_B2A.state_dict(), 'output/netG_B2A.pth')\r\n",
        "    torch.save(netD_A.state_dict(), 'output/netD_A.pth')\r\n",
        "    torch.save(netD_B.state_dict(), 'output/netD_B.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9WV2PiFSIsS"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znK36mlGSK1s"
      },
      "source": [
        "!rm -rf output/A/\r\n",
        "!rm -rf output/B/\r\n",
        "\r\n",
        "import argparse\r\n",
        "import sys\r\n",
        "import os\r\n",
        "\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch\r\n",
        "\r\n",
        "batchSize = 1\r\n",
        "dataroot = TARGET_DIR \r\n",
        "input_nc = 3\r\n",
        "output_nc = 3 \r\n",
        "size = 256 \r\n",
        "cuda = True\r\n",
        "n_cpu = 8\r\n",
        "generator_A2B = 'output/netG_A2B.pth'\r\n",
        "generator_B2A = 'output/netG_B2A.pth'\r\n",
        "\r\n",
        "if torch.cuda.is_available() and not cuda:\r\n",
        "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\r\n",
        "\r\n",
        "###### Definition of variables ######\r\n",
        "# Networks\r\n",
        "netG_A2B = Generator(input_nc, output_nc)\r\n",
        "netG_B2A = Generator(output_nc, input_nc)\r\n",
        "\r\n",
        "if cuda:\r\n",
        "    netG_A2B.cuda()\r\n",
        "    netG_B2A.cuda()\r\n",
        "\r\n",
        "# Load state dicts\r\n",
        "netG_A2B.load_state_dict(torch.load(generator_A2B))\r\n",
        "netG_B2A.load_state_dict(torch.load(generator_B2A))\r\n",
        "\r\n",
        "# Set model's test mode\r\n",
        "netG_A2B.eval()\r\n",
        "netG_B2A.eval()\r\n",
        "\r\n",
        "# Inputs & targets memory allocation\r\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\r\n",
        "input_A = Tensor(batchSize, input_nc, size, size)\r\n",
        "input_B = Tensor(batchSize, output_nc, size, size)\r\n",
        "\r\n",
        "# Dataset loader\r\n",
        "transforms_ = [ transforms.ToTensor(),\r\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\r\n",
        "dataloader = DataLoader(ImageDataset(dataroot, transforms_=transforms_, mode='test'), \r\n",
        "                        batch_size=batchSize, shuffle=False, num_workers=n_cpu)\r\n",
        "###################################\r\n",
        "\r\n",
        "###### Testing######\r\n",
        "\r\n",
        "# Create output dirs if they don't exist\r\n",
        "if not os.path.exists('output/A'):\r\n",
        "    os.makedirs('output/A')\r\n",
        "if not os.path.exists('output/B'):\r\n",
        "    os.makedirs('output/B')\r\n",
        "\r\n",
        "for i, batch in enumerate(dataloader):\r\n",
        "    # Set model input\r\n",
        "    real_A = Variable(input_A.copy_(batch['A']))\r\n",
        "    real_B = Variable(input_B.copy_(batch['B']))\r\n",
        "\r\n",
        "    # Generate output\r\n",
        "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\r\n",
        "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\r\n",
        "\r\n",
        "    # Save image files\r\n",
        "    save_image(fake_A, 'output/A/%04d.png' % (i+1))\r\n",
        "    save_image(fake_B, 'output/B/%04d.png' % (i+1))\r\n",
        "\r\n",
        "    sys.stdout.write('\\rGenerated images %04d of %04d' % (i+1, len(dataloader)))\r\n",
        "\r\n",
        "sys.stdout.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}